python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Ant.pkl --env_name Ant-v4 --exp_name bc_ant --n_iter 1 --expert_data cs285/expert_data/expert_data_Ant-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 4713.7568359375
Eval_StdReturn : 0.0
Eval_MaxReturn : 4713.7568359375
Eval_MinReturn : 4713.7568359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 4681.891673935816
Train_StdReturn : 30.70862278765526
Train_MaxReturn : 4712.600296723471
Train_MinReturn : 4651.18305114816
Train_AverageEpLen : 1000.0
Training Loss : -1.9789094924926758
Train_EnvstepsSoFar : 0
TimeSinceStart : 96.81921219825745
Initial_DataCollection_AverageReturn : 4681.891673935816


python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Ant.pkl --env_name Hopper-v4 --exp_name bc_ant --n_iter 1 --expert_data cs285/expert_data/expert_data_Hopper-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 708.9853515625
Eval_StdReturn : 219.4167022705078
Eval_MaxReturn : 1085.236083984375
Eval_MinReturn : 533.7840576171875
Eval_AverageEpLen : 261.25
Train_AverageReturn : 3717.5129936182307
Train_StdReturn : 0.3530361779417035
Train_MaxReturn : 3717.8660297961724
Train_MinReturn : 3717.159957440289
Train_AverageEpLen : 1000.0
Training Loss : -1.1271556615829468
Train_EnvstepsSoFar : 0
TimeSinceStart : 28.333853244781494

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Ant.pkl --env_name Hopper-v4 --exp_name bc_ant --n_iter 1 --expert_data cs285/expert_data/expert_data_ #--video_log_freq -1

Eval_AverageReturn : 3705.39794921875
Eval_StdReturn : 0.0
Eval_MaxReturn : 3705.39794921875
Eval_MinReturn : 3705.39794921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 4034.7999834965067
Train_StdReturn : 32.8677631311341
Train_MaxReturn : 4067.6677466276406
Train_MinReturn : 4001.9322203653724
Train_AverageEpLen : 1000.0
Training Loss : -1.34160578250885
Train_EnvstepsSoFar : 0
TimeSinceStart : 66.97823905944824
Initial_DataCollection_AverageReturn : 4034.7999834965067

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Ant.pkl --env_name HalfCheetah-v4 --exp_name bc_ant --n_iter 1 --expert_data cs285/expert_data/expert_data_ #--video_log_freq -1

Eval_AverageReturn : 641.1116333007812
Eval_StdReturn : 941.7157592773438
Eval_MaxReturn : 2947.61279296875
Eval_MinReturn : 236.1321563720703
Eval_AverageEpLen : 183.85714285714286
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.6667086482048035
Train_EnvstepsSoFar : 0
TimeSinceStart : 42.960545778274536
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Ant.pkl --env_name Walker2d-v4 --exp_name bc_ant --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 641.1116333007812
Eval_StdReturn : 941.7157592773438
Eval_MaxReturn : 2947.61279296875
Eval_MinReturn : 236.1321563720703
Eval_AverageEpLen : 183.85714285714286
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.6667086482048035
Train_EnvstepsSoFar : 0
TimeSinceStart : 42.960545778274536
Initial_DataCollection_AverageReturn : 5383.310325177668


--------------------------

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Hopper.pkl --env_name Hopper-v4 --exp_name bc_ant --n_iter 1 --expert_data cs285/expert_data/expert_data_Hopper-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 973.355224609375
Eval_StdReturn : 469.2252197265625
Eval_MaxReturn : 1746.2430419921875
Eval_MinReturn : 586.0081787109375
Eval_AverageEpLen : 319.5
Train_AverageReturn : 3717.5129936182307
Train_StdReturn : 0.3530361779417035
Train_MaxReturn : 3717.8660297961724
Train_MinReturn : 3717.159957440289
Train_AverageEpLen : 1000.0
Training Loss : -1.1271556615829468
Train_EnvstepsSoFar : 0
TimeSinceStart : 30.921350717544556
Initial_DataCollection_AverageReturn : 3717.5129936182307

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/HalfCheetah.pkl --env_name HalfCheetah-v4 --exp_name bc_halfcheetah --n_iter 1 --expert_data cs285/expert_data/expert_data_HalfCheetah-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 4087.58447265625
Eval_StdReturn : 0.0
Eval_MaxReturn : 4087.58447265625
Eval_MinReturn : 4087.58447265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 4034.7999834965067
Train_StdReturn : 32.8677631311341
Train_MaxReturn : 4067.6677466276406
Train_MinReturn : 4001.9322203653724
Train_AverageEpLen : 1000.0
Training Loss : -1.34160578250885
Train_EnvstepsSoFar : 0
TimeSinceStart : 77.85885500907898
Initial_DataCollection_AverageReturn : 4034.7999834965067

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 1106.3974609375
Eval_StdReturn : 1227.394287109375
Eval_MaxReturn : 3389.41015625
Eval_MinReturn : 225.87265014648438
Eval_AverageEpLen : 281.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.6667086482048035
Train_EnvstepsSoFar : 0
TimeSinceStart : 51.72740888595581
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=4 #--video_log_freq -1

Eval_AverageReturn : 549.862548828125
Eval_StdReturn : 671.3082885742188
Eval_MaxReturn : 2192.6953125
Eval_MinReturn : 245.51638793945312
Eval_AverageEpLen : 171.14285714285714
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.7327898144721985
Train_EnvstepsSoFar : 0
TimeSinceStart : 17.27382183074951

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=8 #--video_log_freq -1

Eval_AverageReturn : 1286.3984375
Eval_StdReturn : 1098.8443603515625
Eval_MaxReturn : 2385.242919921875
Eval_MinReturn : 187.55406188964844
Eval_AverageEpLen : 561.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.3518109917640686
Train_EnvstepsSoFar : 0
TimeSinceStart : 65.42752003669739
Initial_DataCollection_AverageReturn : 5383.310325177668



python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Ant.pkl --env_name Ant-v4 --exp_name bc_ant --n_iter 1 --expert_data cs285/expert_data/expert_data_Ant-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 4713.7568359375
Eval_StdReturn : 0.0
Eval_MaxReturn : 4713.7568359375
Eval_MinReturn : 4713.7568359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 4681.891673935816
Train_StdReturn : 30.70862278765526
Train_MaxReturn : 4712.600296723471
Train_MinReturn : 4651.18305114816
Train_AverageEpLen : 1000.0
Training Loss : -1.9789094924926758
Train_EnvstepsSoFar : 0
TimeSinceStart : 96.81921219825745
Initial_DataCollection_AverageReturn : 4681.891673935816

performance ratio = 4713/4681

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 1106.3974609375
Eval_StdReturn : 1227.394287109375
Eval_MaxReturn : 3389.41015625
Eval_MinReturn : 225.87265014648438
Eval_AverageEpLen : 281.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.6667086482048035
Train_EnvstepsSoFar : 0
TimeSinceStart : 51.72740888595581
Initial_DataCollection_AverageReturn : 5383.310325177668

performance ratio = 1106/5383

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Hopper.pkl --env_name Hopper-v4 --exp_name bc_ant --n_iter 1 --expert_data cs285/expert_data/expert_data_Hopper-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 973.355224609375
Eval_StdReturn : 469.2252197265625
Eval_MaxReturn : 1746.2430419921875
Eval_MinReturn : 586.0081787109375
Eval_AverageEpLen : 319.5
Train_AverageReturn : 3717.5129936182307
Train_StdReturn : 0.3530361779417035
Train_MaxReturn : 3717.8660297961724
Train_MinReturn : 3717.159957440289
Train_AverageEpLen : 1000.0
Training Loss : -1.1271556615829468
Train_EnvstepsSoFar : 0
TimeSinceStart : 30.921350717544556
Initial_DataCollection_AverageReturn : 3717.5129936182307

performance ratio = 973/3717

--------------------------

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Ant.pkl --env_name Ant-v4 --exp_name bc_ant --n_iter 1 --expert_data cs285/expert_data/expert_data_Ant-v4.pkl --ep_len=1000 --eval_batch_size=10000 #--video_log_freq -1

Eval_AverageReturn : 3902.249755859375
Eval_StdReturn : 1401.2403564453125
Eval_MaxReturn : 4759.93359375
Eval_MinReturn : 850.2813720703125
Eval_AverageEpLen : 834.5833333333334
Train_AverageReturn : 4681.891673935816
Train_StdReturn : 30.70862278765526
Train_MaxReturn : 4712.600296723471
Train_MinReturn : 4651.18305114816
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.833477155736703
Training Loss : -1.9789094924926758
Train_EnvstepsSoFar : 0
TimeSinceStart : 79.3958740234375
Initial_DataCollection_AverageReturn : 4681.891673935816

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --ep_len=1000 --eval_batch_size=10000 #--video_log_freq -1

Eval_AverageReturn : 1218.0789794921875
Eval_StdReturn : 1411.2138671875
Eval_MaxReturn : 4861.7353515625
Eval_MinReturn : 1.0501681566238403
Eval_AverageEpLen : 297.19444444444446
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.2262695081491492
Training Loss : -0.6667086482048035
Train_EnvstepsSoFar : 0
TimeSinceStart : 47.6527738571167
Initial_DataCollection_AverageReturn : 5383.310325177668


----------------------------

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 1106.3974609375
Eval_StdReturn : 1227.394287109375
Eval_MaxReturn : 3389.41015625
Eval_MinReturn : 225.87265014648438
Eval_AverageEpLen : 281.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.6667086482048035
Train_EnvstepsSoFar : 0
TimeSinceStart : 51.72740888595581
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=4 #--video_log_freq -1

Eval_AverageReturn : 549.862548828125
Eval_StdReturn : 671.3082885742188
Eval_MaxReturn : 2192.6953125
Eval_MinReturn : 245.51638793945312
Eval_AverageEpLen : 171.14285714285714
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.7327898144721985
Train_EnvstepsSoFar : 0
TimeSinceStart : 17.27382183074951

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=8 #--video_log_freq -1

Eval_AverageReturn : 1286.3984375
Eval_StdReturn : 1098.8443603515625
Eval_MaxReturn : 2385.242919921875
Eval_MinReturn : 187.55406188964844
Eval_AverageEpLen : 561.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.3518109917640686
Train_EnvstepsSoFar : 0
TimeSinceStart : 65.42752003669739
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=12 #--video_log_freq -1

Eval_AverageReturn : 114.66270446777344
Eval_StdReturn : 74.0755615234375
Eval_MaxReturn : 264.91534423828125
Eval_MinReturn : 3.8619537353515625
Eval_AverageEpLen : 105.1
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.021299664619276647
Training Loss : 0.2285430133342743
Train_EnvstepsSoFar : 0
TimeSinceStart : 25.546361207962036
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=16 #--video_log_freq -1

Eval_AverageReturn : 1.247044324874878
Eval_StdReturn : 8.58582878112793
Eval_MaxReturn : 26.61944007873535
Eval_MinReturn : -19.429893493652344
Eval_AverageEpLen : 27.216216216216218
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.00023165009065936044
Training Loss : 1.32883620262146
Train_EnvstepsSoFar : 0
TimeSinceStart : 10.975441932678223
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=20 #--video_log_freq -1

Eval_AverageReturn : 6.884927272796631
Eval_StdReturn : 9.5217866897583
Eval_MaxReturn : 45.70391082763672
Eval_MinReturn : -5.519145965576172
Eval_AverageEpLen : 27.594594594594593
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.0012789393248603784
Training Loss : 1.3638454675674438
Train_EnvstepsSoFar : 0
TimeSinceStart : 16.240965127944946
Initial_DataCollection_AverageReturn : 5383.310325177668

-----------------

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl #--video_log_freq -1

Eval_AverageReturn : 1106.3974609375
Eval_StdReturn : 1227.394287109375
Eval_MaxReturn : 3389.41015625
Eval_MinReturn : 225.87265014648438
Eval_AverageEpLen : 281.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Training Loss : -0.6667086482048035
Train_EnvstepsSoFar : 0
TimeSinceStart : 51.72740888595581
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=2 --num_agent_train_steps_per_iter=2000 #--video_log_freq -1

Eval_AverageReturn : 2464.34375
Eval_StdReturn : 2185.99609375
Eval_MaxReturn : 4650.33984375
Eval_MinReturn : 278.3475646972656
Eval_AverageEpLen : 524.5
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.4577747893288444
Training Loss : -1.0642017126083374
Train_EnvstepsSoFar : 0
TimeSinceStart : 13.80420708656311
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=2 --num_agent_train_steps_per_iter=4000 #--video_log_freq -1

Eval_AverageReturn : 2664.4990234375
Eval_StdReturn : 1998.6192626953125
Eval_MaxReturn : 5153.77490234375
Eval_MinReturn : 260.4010314941406
Eval_AverageEpLen : 554.6666666666666
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.4949554943871013
Training Loss : -1.1238449811935425
Train_EnvstepsSoFar : 0
TimeSinceStart : 15.634878158569336
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=2 --num_agent_train_steps_per_iter=8000 #--video_log_freq -1

Eval_AverageReturn : 2709.1435546875
Eval_StdReturn : 2475.1650390625
Eval_MaxReturn : 5184.30859375
Eval_MinReturn : 233.97869873046875
Eval_AverageEpLen : 553.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.5032486316118305
Training Loss : -1.4026566743850708
Train_EnvstepsSoFar : 0
TimeSinceStart : 71.97852206230164
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=2 --num_agent_train_steps_per_iter=16000 #--video_log_freq -1

Eval_AverageReturn : 5211.2685546875
Eval_StdReturn : 0.0
Eval_MaxReturn : 5211.2685546875
Eval_MinReturn : 5211.2685546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.9680416397907564
Training Loss : -0.8730127215385437
Train_EnvstepsSoFar : 0
TimeSinceStart : 89.79228401184082
Initial_DataCollection_AverageReturn : 5383.310325177668


python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=2 --num_agent_train_steps_per_iter=32000 #--video_log_freq -1

Eval_AverageReturn : 5286.798828125
Eval_StdReturn : 0.0
Eval_MaxReturn : 5286.798828125
Eval_MinReturn : 5286.798828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.9820720911069746
Training Loss : -1.7236595153808594
Train_EnvstepsSoFar : 0
TimeSinceStart : 131.9501121044159
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=2 --num_agent_train_steps_per_iter=64000 #--video_log_freq -1

Eval_AverageReturn : 5400.642578125
Eval_StdReturn : 0.0
Eval_MaxReturn : 5400.642578125
Eval_MinReturn : 5400.642578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 1.0032196273111489
Training Loss : -1.644033432006836
Train_EnvstepsSoFar : 0
TimeSinceStart : 137.23469519615173
Initial_DataCollection_AverageReturn : 5383.310325177668

python cs285/scripts/run_hw1.py --expert_policy_file cs285/policies/experts/Walker2d.pkl --env_name Walker2d-v4 --exp_name bc_walker2d --n_iter 1 --expert_data cs285/expert_data/expert_data_Walker2d-v4.pkl --n_layers=2 --num_agent_train_steps_per_iter=128000 #--video_log_freq -1

Eval_AverageReturn : 5032.76171875
Eval_StdReturn : 0.0
Eval_MaxReturn : 5032.76171875
Eval_MinReturn : 5032.76171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 5383.310325177668
Train_StdReturn : 54.15251563871789
Train_MaxReturn : 5437.462840816386
Train_MinReturn : 5329.1578095389505
Train_AverageEpLen : 1000.0
Performance_Ratio : 0.9348823334987475
Training Loss : -1.731462001800537
Train_EnvstepsSoFar : 0
TimeSinceStart : 259.30706882476807
Initial_DataCollection_AverageReturn : 5383.310325177668

why increasing training steps help improve result
Training Process
Each step:
- Processes same expert data
- Updates policy parameters
- Minimizes negative log likelihood
More steps:
- More parameter refinement
- Better expert behavior matching
- Finer policy optimization
Think of it like practicing a skill - more repetitions generally lead to better performance.

when to stop increasing training steps
Plan to determine optimal training steps
1.Monitor Metrics
- Training loss convergence
- Eval return stability
- Time efficiency threshold
2. Implementation Steps
- Add early stopping
- Track validation metrics
- Set convergence criteria
3. Stopping Criteria
- Loss plateaus (change < threshold)
- Max time limit reached
- Eval return saturates
- Overfitting detected (eval < train)

